<html>
<head>
</head>
<body>
	<h1>
		MicroProfiler</h1>
	<p>
		MicroProfiler is a simple way to see in <strong>realtime</strong> what your application
		is busy with. It is almost effortless to add it to an existing VisualStudio C++
		project.</p>
	<h2>
		Preface</h2>
	<p>
		Profilers are split into two major categories: sampling and instrumenting.
	</p>
	<p>
		Major advantage of sampling profilers is that they are very easy to run and require
		almost zero steps to prepare executable image for profiling. On the other hand,
		the shortcoming of using sampling profiler is that it provides only statistical
		information about functions in use. To be strict - sampling profiler provides only
		the number of hits into a function in series of stack snapshots, which renders it
		hard to fine-tune small or rarely called functions. For this tasks it may take too
		long time to collect enough samples to build reasonable statistics.
	</p>
	<p>
		Instrumenting profiling is another way of building application performance profile
		- it collects times and numbers of calls to each function in the scope being profiled.
		This can be done by either patching the image (via injecting JMPs to profiling points)
		or via compiler support enabling user-defined functions to be called at the begin/end
		of each profiled function. This approach allows precise collection of call metrics
		by the price of observable application's performance degradation. Hopefully, this
		degradation (induced by a huge amount of function entry/exit collections) can be
		cancelled in profiling results.
	</p>
	<p>
		VisualStudio Team System Suite includes both types profiler, but:</p>
	<ol>
		<li>VSTS costs money. A lot of them, actually; </li>
		<li>It is buggy and sometimes just fails (for very complex/large projects) for unknown
			or hardly recognized reason. </li>
	</ol>
	<p>
		So, I decided to implement an instrumenting profiler of my own. It is consisted
		of two major parts: collection library and frontend/postprocessing server. Both
		parts are interacting via COM-based IPC with custom marshaled data.
	</p>
	<ul>
		<li><strong>The Collector</strong> (micro-profiler.dll) is linked to the profiled application
			and exports <code>_penter</code> / <code>_pexit</code> functions that are called
			by prolog/epilog function parts of the instrumented scope. It collects entry/exit
			times + addresses to call trace buffers which are regularly inspected to build shadow
			stacks and capture # calls / exclusive/inclusive time statistics. Captured statistics
			is passed over the RPC to the Frontend; </li>
		<li><strong>The Frontend</strong> (micro-profiler-frontend.exe) is an out-of-process
			COM server, being invoked by Collector's instance. It aggregates incoming statistics,
			allowing user to sort it by different aspects. User may also clear previously collected
			statistics. </li>
	</ul>
	<h2>
		Usage Guidelines</h2>
	<p>
		There several steps to add profiling support to your VisualStudio project (look
		for required files in the attachment section):
	</p>
	<ol>
		<li>Add construction/destruction of the profiler's frontend to your project:
			<ol>
				<li>If executable's source project is allowed for modification: add global instance
					of <code>micro_profiler::profiler_frontend</code> class declared in <code>entry.h</code>
					include file. The object won't be used by your application, so you may enclose it
					in an anonymous namespace and move to a separate .cpp-file; </li>
				<li>TBD: adding profiling support to DLLs; </li>
			</ol>
		</li>
		<li>Specify the scope to be profiled:
			<ol>
				<li>Apply <strong>/GH /Gh</strong> command line options to compiler tool of your VS-project;
				</li>
				<li>Or apply <strong>/GH /Gh</strong> command line options to compiler tool of specific
					source (.cpp) file(s) you want to profile; </li>
			</ol>
		</li>
		<li>Link your project against <code>micro-profiler.lib</code>. Make sure your project
			is not referencing any other library that exports <code>_penter()</code> and/or
			<code>_pexit()</code> function(s). In CQG projects this function is exported by
			exe_trace.dll. You can disable export by removing its <code>__declspec(dllexport)</code>
			specification (defined via EXE_TRACE_API macro); </li>
		<li>Register micro-profiler.dll (this registers frontend and proxy/stub code for statistics
			IPC): <code>regsvr32 micro-profiler.dll</code>. Please note, that correct registration
			on Windows Vista/7 require elevated privileges; </li>
		<li>Ensure that micro-profiler.dll is placed to the same directory where your profiled
			image (exe/dll) resides. </li>
	</ol>
	<h2>
		Building Sources Prerequisites</h2>
	<p>
		In order to build profiler you must have DIA SDK available in include/library paths.
		I have set mine to <code>"$(VSInstallDir)DIA SDK\include"</code> and <code>"$(VSInstallDir)DIA
			SDK\lib"</code> correspondingly. You may build sources using VisualStudio 2008
		or 2010. Profiler core (micro-profiler.dll) is being developed using TDD, so you
		may run its tests, by selecting <code>tests</code> project as startup and running
		it. VisualStudio integrated testing framework is used.
	</p>
	<h2>
		Future Development</h2>
	<ul>
		<li>Collection of child calls statistics. This will allow defining the most hot execution
			paths at a glance; </li>
		<li>Redevelopment of a frontend using TDD - otherwise I cannot be sure it has production
			quality; </li>
		<li>Performance improvement - there is a potential of up to x3 times _penter/_pexit
			speedup; </li>
		<li>X64 support - it just requires some more ASM-hacking :)</li>
		<li>Time-based profile - a chart with ability to snap statistics profile to a specific
			time range giving user an opportunity to see what was happening at that exact moment
			of time. </li>
	</ul>
	<h2>
		Revision history
	</h2>
	<h3>
		r89
	</h3>
	<ul>
		<li>Collector and Frontend are merged into one dll. You have to register only one file
			- the dll. Frontend is run from a surrogate COM-process; </li>
		<li>Recursion control: inclusive times are collected only for top-level function calls,
			plus maximal recursion depth is displayed for a function; </li>
		<li>Significant speedup in analysis thread by using address-specific hash-functions
			for statistics and recursion level dictionaries; </li>
		<li>Test runner (run-tests.cmd) is included into deployment package to ensure platform
			compatibility. Requires VS2008 with unit-testing framework installed. </li>
	</ul>
	<h3>
		r68</h3>
	<ul>
		<li>Initial revision. Separate collector/frontend parts. </li>
	</ul>
	<p />
</body>
</html>
